# Model Sharding
Model sharding is a technique used to split a large machine learning model (like an LLM) across multiple devices (e.g., GPUs, TPUs, or nodes) so that each device holds and processes only a portion of the model. This allows you to run models that are too large to fit into a single deviceâ€™s memory.
